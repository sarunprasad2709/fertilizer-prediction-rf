# -*- coding: utf-8 -*-
"""fertilizer_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZDxzc_3vFLget1gyATO8zO1X4lgoVicR
"""

# =============================================================================
# FERTILIZER PREDICTION CHALLENGE - GOOGLE COLAB NOTEBOOK
# Random Forest Model with One-Hot Encoding and MAP@3 Evaluation
# =============================================================================

# Cell 1: Setup and Installation
print("ğŸš€ Setting up environment for Fertilizer Prediction Challenge")
print("=" * 60)

# Install required packages
!pip install -q kaggle pandas numpy scikit-learn matplotlib seaborn

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report
import warnings
import os
import zipfile
from google.colab import files
from google.colab import drive
import json

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')

print("âœ… All packages installed successfully!")

# =============================================================================
# Cell 2: Kaggle API Setup
# =============================================================================

print("\nğŸ” Setting up Kaggle API credentials")
print("=" * 60)

# Method 1: Upload kaggle.json file
print("Please upload your kaggle.json file when prompted...")
try:
    uploaded = files.upload()

    # Move kaggle.json to the right location
    os.makedirs('/root/.kaggle', exist_ok=True)

    for filename in uploaded.keys():
        if filename == 'kaggle.json':
            os.rename(filename, '/root/.kaggle/kaggle.json')
            os.chmod('/root/.kaggle/kaggle.json', 0o600)
            print("âœ… Kaggle credentials set up successfully!")
            break
    else:
        print("âŒ kaggle.json not found in uploaded files")

except Exception as e:
    print(f"âŒ Error setting up Kaggle credentials: {e}")
    print("\nğŸ“ Alternative method:")
    print("1. Go to https://www.kaggle.com/account")
    print("2. Click 'Create New API Token'")
    print("3. Upload the downloaded kaggle.json file when prompted above")

# =============================================================================
# Cell 3: Download Dataset
# =============================================================================

print("\nğŸ“¥ Downloading dataset from Kaggle")
print("=" * 60)

# Download the competition dataset
try:
    # Download competition files
    !kaggle competitions download -c playground-series-s5e6

    # Extract the files
    with zipfile.ZipFile('playground-series-s5e6.zip', 'r') as zip_ref:
        zip_ref.extractall('.')

    # List downloaded files
    print("\nğŸ“‚ Downloaded files:")
    for file in os.listdir('.'):
        if file.endswith('.csv'):
            size = os.path.getsize(file) / (1024*1024)  # Size in MB
            print(f"  â€¢ {file} ({size:.1f} MB)")

    print("âœ… Dataset downloaded successfully!")

except Exception as e:
    print(f"âŒ Error downloading dataset: {e}")
    print("Please check your Kaggle API setup and competition access")

# =============================================================================
# Cell 4: Data Loading and Exploration
# =============================================================================

print("\nğŸ” Loading and exploring the dataset")
print("=" * 60)

def load_and_explore_data():
    """Load and explore the dataset"""
    try:
        # Load datasets
        train_df = pd.read_csv('train.csv')
        test_df = pd.read_csv('test.csv')
        sample_submission = pd.read_csv('sample_submission.csv')

        print(f"ğŸ“Š Dataset Shapes:")
        print(f"  â€¢ Training data: {train_df.shape}")
        print(f"  â€¢ Test data: {test_df.shape}")
        print(f"  â€¢ Sample submission: {sample_submission.shape}")

        print(f"\nğŸ“‹ Training Data Info:")
        print(f"  â€¢ Columns: {list(train_df.columns)}")
        print(f"  â€¢ Data types:")
        for col in train_df.columns:
            print(f"    - {col}: {train_df[col].dtype}")

        print(f"\nğŸ¯ Target Variable Analysis:")
        target_counts = train_df['Fertilizer Name'].value_counts()
        print(f"  â€¢ Unique fertilizers: {len(target_counts)}")
        print(f"  â€¢ Most common fertilizers:")
        for i, (fertilizer, count) in enumerate(target_counts.head(10).items()):
            print(f"    {i+1}. {fertilizer}: {count} samples")

        # Display sample data
        print(f"\nğŸ“ Sample Training Data:")
        print(train_df.head())

        print(f"\nğŸ“ Sample Test Data:")
        print(test_df.head())

        print(f"\nğŸ“ Sample Submission Format:")
        print(sample_submission.head())

        return train_df, test_df, sample_submission

    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return None, None, None

# Load the data
train_df, test_df, sample_submission = load_and_explore_data()

# =============================================================================
# Cell 5: Data Visualization
# =============================================================================

if train_df is not None:
    print("\nğŸ“Š Data Visualization")
    print("=" * 60)

    # Create visualizations
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # 1. Target distribution
    target_counts = train_df['Fertilizer Name'].value_counts().head(15)
    axes[0, 0].bar(range(len(target_counts)), target_counts.values)
    axes[0, 0].set_title('Top 15 Fertilizer Types Distribution')
    axes[0, 0].set_xlabel('Fertilizer Type (Index)')
    axes[0, 0].set_ylabel('Count')
    axes[0, 0].tick_params(axis='x', rotation=45)

    # 2. Missing values heatmap
    missing_data = train_df.isnull().sum()
    if missing_data.sum() > 0:
        axes[0, 1].bar(missing_data.index, missing_data.values)
        axes[0, 1].set_title('Missing Values by Column')
        axes[0, 1].tick_params(axis='x', rotation=45)
    else:
        axes[0, 1].text(0.5, 0.5, 'No Missing Values', ha='center', va='center',
                       transform=axes[0, 1].transAxes, fontsize=14)
        axes[0, 1].set_title('Missing Values Analysis')

    # 3. Data types distribution
    dtype_counts = train_df.dtypes.value_counts()
    axes[1, 0].pie(dtype_counts.values, labels=dtype_counts.index, autopct='%1.1f%%')
    axes[1, 0].set_title('Data Types Distribution')

    # 4. Dataset size comparison
    sizes = [len(train_df), len(test_df)]
    labels = ['Training Set', 'Test Set']
    axes[1, 1].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
    axes[1, 1].set_title('Dataset Size Comparison')

    plt.tight_layout()
    plt.show()

# =============================================================================
# Cell 6: Data Preprocessing Functions
# =============================================================================

print("\nğŸ”§ Setting up data preprocessing functions")
print("=" * 60)

def preprocess_data(train_df, test_df):
    """
    Comprehensive data preprocessing with one-hot encoding
    """
    print("ğŸ”„ Starting data preprocessing...")

    # Separate features and target
    if 'Fertilizer Name' in train_df.columns:
        X_train = train_df.drop(['Fertilizer Name'], axis=1)
        y_train = train_df['Fertilizer Name']
    else:
        X_train = train_df.copy()
        y_train = None

    X_test = test_df.copy()

    print(f"  â€¢ Training features shape: {X_train.shape}")
    print(f"  â€¢ Test features shape: {X_test.shape}")

    # Handle missing values
    print("  â€¢ Handling missing values...")
    for col in X_train.columns:
        if X_train[col].dtype == 'object':
            # Categorical: fill with mode
            mode_val = X_train[col].mode().iloc[0] if not X_train[col].mode().empty else 'Unknown'
            X_train[col] = X_train[col].fillna(mode_val)
            X_test[col] = X_test[col].fillna(mode_val)
        else:
            # Numerical: fill with mean
            mean_val = X_train[col].mean()
            X_train[col] = X_train[col].fillna(mean_val)
            X_test[col] = X_test[col].fillna(mean_val)

    # Identify feature types
    categorical_features = []
    numerical_features = []

    for col in X_train.columns:
        if col == 'id':
            continue  # Skip ID column
        elif X_train[col].dtype == 'object':
            categorical_features.append(col)
        else:
            numerical_features.append(col)

    print(f"  â€¢ Categorical features ({len(categorical_features)}): {categorical_features}")
    print(f"  â€¢ Numerical features ({len(numerical_features)}): {numerical_features}")

    # Create preprocessing pipeline
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', 'passthrough', numerical_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        remainder='drop'  # Drop any remaining columns (like 'id')
    )

    print("âœ… Preprocessing pipeline created successfully!")

    return X_train, X_test, y_train, preprocessor, categorical_features, numerical_features

# =============================================================================
# Cell 7: Random Forest Model Training
# =============================================================================

def train_random_forest_model(X_train, y_train, preprocessor):
    """
    Train Random Forest model with preprocessing pipeline
    """
    print("ğŸŒ² Training Random Forest model...")

    # Create complete pipeline
    rf_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(
            n_estimators=100,
            max_depth=20,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1,
            verbose=1
        ))
    ])

    # Split for validation
    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )

    print(f"  â€¢ Training set: {X_train_split.shape[0]} samples")
    print(f"  â€¢ Validation set: {X_val_split.shape[0]} samples")

    # Train model
    print("  â€¢ Fitting Random Forest...")
    rf_pipeline.fit(X_train_split, y_train_split)

    # Validate model
    print("  â€¢ Evaluating on validation set...")
    val_predictions = rf_pipeline.predict(X_val_split)
    val_accuracy = accuracy_score(y_val_split, val_predictions)

    print(f"  â€¢ Validation Accuracy: {val_accuracy:.4f}")

    # Calculate MAP@3 on validation set
    val_map3 = calculate_map3_validation(rf_pipeline, X_val_split, y_val_split)
    print(f"  â€¢ Validation MAP@3: {val_map3:.4f}")

    # Train on full dataset
    print("  â€¢ Training on full dataset...")
    rf_pipeline.fit(X_train, y_train)

    print("âœ… Model training completed!")

    return rf_pipeline

def calculate_map3_validation(model, X_val, y_val):
    """Calculate MAP@3 for validation set"""
    try:
        pred_proba = model.predict_proba(X_val)
        classes = model.classes_

        total_ap = 0
        for i, true_label in enumerate(y_val):
            # Get top 3 predictions
            top3_indices = np.argsort(pred_proba[i])[-3:][::-1]
            top3_predictions = [classes[idx] for idx in top3_indices]

            # Calculate AP for this sample
            ap = 0
            for j, pred in enumerate(top3_predictions):
                if pred == true_label:
                    ap = 1.0 / (j + 1)
                    break

            total_ap += ap

        return total_ap / len(y_val)
    except:
        return 0.0

# =============================================================================
# Cell 8: Prediction Generation
# =============================================================================

def generate_top3_predictions(model, X_test, test_df):
    """
    Generate top 3 predictions for each test sample
    """
    print("ğŸ¯ Generating predictions...")

    # Get prediction probabilities
    print("  â€¢ Computing prediction probabilities...")
    pred_proba = model.predict_proba(X_test)
    classes = model.classes_

    print(f"  â€¢ Number of classes: {len(classes)}")
    print(f"  â€¢ Test samples: {len(pred_proba)}")

    # Generate top 3 predictions
    predictions = []
    print("  â€¢ Generating top-3 predictions...")

    for i in range(len(pred_proba)):
        # Get indices of top 3 probabilities
        top3_indices = np.argsort(pred_proba[i])[-3:][::-1]

        # Get corresponding class names
        top3_classes = [classes[idx] for idx in top3_indices]

        # Join with spaces as required by submission format
        prediction_string = ' '.join(top3_classes)
        predictions.append(prediction_string)

        # Progress indicator
        if (i + 1) % 10000 == 0:
            print(f"    Processed {i + 1}/{len(pred_proba)} samples")

    # Create submission dataframe
    submission_df = pd.DataFrame({
        'id': test_df['id'],
        'Fertilizer Name': predictions
    })

    print("âœ… Predictions generated successfully!")

    return submission_df

# =============================================================================
# Cell 9: MAP@3 Metric Implementation
# =============================================================================

def calculate_map3(y_true, y_pred_top3):
    """
    Calculate Mean Average Precision @ 3
    """
    def average_precision_k(actual, predicted, k=3):
        """Calculate AP@k for a single sample"""
        if len(predicted) > k:
            predicted = predicted[:k]

        score = 0.0
        num_hits = 0.0

        for i, p in enumerate(predicted):
            if p == actual:
                num_hits += 1.0
                score += num_hits / (i + 1.0)
                break  # Stop after first correct prediction

        return score

    # Calculate AP for each sample and take mean
    ap_scores = []
    for true_label, pred_string in zip(y_true, y_pred_top3):
        predicted_labels = pred_string.split()
        ap = average_precision_k(true_label, predicted_labels, k=3)
        ap_scores.append(ap)

    return np.mean(ap_scores)

print("âœ… All functions defined successfully!")

# =============================================================================
# Cell 10: Model Training and Evaluation
# =============================================================================

if train_df is not None and test_df is not None:
    print("\nğŸš€ Starting model training pipeline")
    print("=" * 60)

    # Preprocess data
    X_train, X_test, y_train, preprocessor, cat_features, num_features = preprocess_data(train_df, test_df)

    # Train model
    model = train_random_forest_model(X_train, y_train, preprocessor)

    # Generate predictions
    submission_df = generate_top3_predictions(model, X_test, test_df)

    print(f"\nğŸ“‹ Submission Summary:")
    print(f"  â€¢ Submission shape: {submission_df.shape}")
    print(f"  â€¢ Sample predictions:")
    print(submission_df.head(10))

# =============================================================================
# Cell 11: Feature Importance Analysis
# =============================================================================

if 'model' in locals():
    print("\nğŸ“Š Feature Importance Analysis")
    print("=" * 60)

    try:
        # Get feature names after preprocessing
        feature_names = []

        # Add numerical features
        feature_names.extend(num_features)

        # Add one-hot encoded categorical features
        if cat_features:
            cat_feature_names = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_features)
            feature_names.extend(cat_feature_names)

        # Get feature importances
        importances = model.named_steps['classifier'].feature_importances_

        # Create feature importance dataframe
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)

        print(f"ğŸ“ˆ Top 15 Most Important Features:")
        print(feature_importance_df.head(15).to_string(index=False))

        # Plot feature importance
        plt.figure(figsize=(12, 8))
        top_features = feature_importance_df.head(20)
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('Feature Importance')
        plt.title('Top 20 Feature Importances - Random Forest')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"âŒ Error calculating feature importance: {e}")

# =============================================================================
# Cell 12: Save Submission File
# =============================================================================

if 'submission_df' in locals():
    print("\nğŸ’¾ Saving submission file")
    print("=" * 60)

    # Save to CSV
    submission_df.to_csv('submission.csv', index=False)

    print(f"âœ… Submission saved as 'submission.csv'")
    print(f"ğŸ“Š Final submission statistics:")
    print(f"  â€¢ Total predictions: {len(submission_df)}")
    print(f"  â€¢ File size: {os.path.getsize('submission.csv')} bytes")

    # Validate submission format
    print(f"\nğŸ” Submission validation:")
    print(f"  â€¢ Required columns: {list(submission_df.columns) == ['id', 'Fertilizer Name']}")
    print(f"  â€¢ No missing values: {submission_df.isnull().sum().sum() == 0}")
    print(f"  â€¢ All IDs present: {len(submission_df['id'].unique()) == len(submission_df)}")

    # Sample submission content
    print(f"\nğŸ“ Sample submission content:")
    print(submission_df.head(10).to_string(index=False))

    # Download file
    print(f"\nâ¬‡ï¸ Downloading submission file...")
    files.download('submission.csv')

# =============================================================================
# Cell 13: Model Performance Summary
# =============================================================================

print("\nğŸ† FINAL PERFORMANCE SUMMARY")
print("=" * 60)

if 'model' in locals() and 'submission_df' in locals():
    print(f"âœ… Model Training: COMPLETED")
    print(f"âœ… Predictions Generated: {len(submission_df)} samples")
    print(f"âœ… Submission File: Created and downloaded")

    print(f"\nğŸ“Š Model Configuration:")
    print(f"  â€¢ Algorithm: Random Forest")
    print(f"  â€¢ Estimators: 100")
    print(f"  â€¢ Max Depth: 20")
    print(f"  â€¢ Preprocessing: One-Hot Encoding")
    print(f"  â€¢ Features: {len(num_features)} numerical + {len(cat_features)} categorical")

    print(f"\nğŸ¯ Submission Details:")
    print(f"  â€¢ Format: Top-3 predictions per sample")
    print(f"  â€¢ Evaluation Metric: MAP@3")
    print(f"  â€¢ File: submission.csv")
    print(f"  â€¢ Ready for Kaggle submission: âœ…")

else:
    print(f"âŒ Model training incomplete. Please check the previous cells for errors.")

print(f"\nğŸš€ Next Steps:")
print(f"  1. Download the submission.csv file")
print(f"  2. Go to the Kaggle competition page")
print(f"  3. Submit your predictions")
print(f"  4. Check your leaderboard position!")

print(f"\nğŸ”§ For improvements, consider:")
print(f"  â€¢ Hyperparameter tuning (GridSearchCV)")
print(f"  â€¢ Feature engineering")
print(f"  â€¢ Ensemble methods")
print(f"  â€¢ Cross-validation")

print("\n" + "=" * 60)
print("ğŸ‰ FERTILIZER PREDICTION CHALLENGE COMPLETED!")
print("=" * 60)